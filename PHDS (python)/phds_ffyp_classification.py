# -*- coding: utf-8 -*-
"""PHDS-FFYP-classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1w3XPnOkQu3jVY-YFWcWCUVKGA4jHFQ2U

**Download dataset from Google Drive**
"""

!unzip "/content/drive/MyDrive/dataset (70-30).zip"

"""## Load dataset"""

# Commented out IPython magic to ensure Python compatibility.
# %pylab inline
import matplotlib.pyplot as plt
import matplotlib.image as npimg
img = npimg.imread('/content/dataset (70-30)/training/healthy/000bf685-b305-408b-91f4-37030f8e62db___GH_HL Leaf 308.1_180deg.JPG')
imgplot = plt.imshow(img)
plt.show()

img = npimg.imread('/content/dataset (70-30)/training/unhealthy/0051e5e8-d1c4-4a84-bf3a-a426cdad6285___RS_LB 4640.JPG')
imgplot = plt.imshow(img)
plt.show()

"""## Import libraries"""

import tensorflow as tf

import tensorflow
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D, Activation
from tensorflow.keras.preprocessing import image
import matplotlib.pyplot as plt
import matplotlib.image as npimg

"""## Designing model

**initialize parameters**
"""

img_width, img_height = 150, 150
train_data_dir  = r"/content/dataset (70-30)/training"
valid_data_dir = r"/content/dataset (70-30)/validation"
nb_training_sample = 100
nb_validation_sample = 100
epochs = 20
batch_size = 25

"""shape of image"""

import tensorflow.keras.backend as k
  if k.image_data_format()=='channel first':
    input_shape = (3, img_width, img_height)
  else:
    input_shape = (img_width, img_height, 3)

"""**generating train model**"""

# DATA AUGMENTATION
train_datagen = ImageDataGenerator(
    rescale = 1/255,
    shear_range = 0.2,
    zoom_range = 0.2,
    horizontal_flip = True
)
valid_datagen = ImageDataGenerator(rescale=1/255)

# DATA GENERATION
train_generator = train_datagen.flow_from_directory(
    train_data_dir,
    target_size = (img_width, img_height),
    batch_size = batch_size,
    class_mode = 'binary',
    classes = ['healthy', 'unhealthy']
)

validation_generator = valid_datagen.flow_from_directory(
    valid_data_dir,
    target_size = (img_width, img_height),
    batch_size = batch_size,
    class_mode ='binary',
    classes = ['healthy', 'unhealthy']
)

"""**visual representation of ImageDataGenerator**"""

plt.figure(figsize=(12,12))
# label = ['a','b','c','d','e','f','g','h','i',]
for i in range(0, 12):
  plt.subplot(5,4,i+1)
  for X_batch, Y_batch in train_generator:
    image = X_batch[0]
    # plt.label(label[image])
    plt.imshow(image)
    break

plt.tight_layout()
plt.show()

"""# Build CNN model"""

model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=input_shape),
    tf.keras.layers.MaxPooling2D(2,2),

    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
   
    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    
    tf.keras.layers.Flatten(),
   
    tf.keras.layers.Dense(512, activation='relu'),
    
    tf.keras.layers.Dense(1, activation='sigmoid')                    
])
model.summary()

"""**compile model**"""

model.compile(
    optimizer = 'adam'(lr=0.001),
    loss = 'binary_crossentropy',
    metrics = ['accuracy']
)
model.summary()

"""**fit model**"""

training = model.fit_generator(
    train_generator,
    steps_per_epoch = nb_training_sample,
    epochs = epochs,
    validation_data = validation_generator,
    validation_steps = nb_validation_sample
)

model.save_weights('PHDS_model.h5')

"""## find accuracy score"""

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
# %matplotlib inline

print(training.history.keys())

plt.plot(training.history['accuracy'])
plt.plot(training.history['val_accuracy'])
plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc = 'upper left')
plt.show

jupplt.plot(training.history['loss'])
plt.plot(training.history['val_loss'])
plt.title('Model Loss')
plt.ylabel('Loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc = 'upper left')
plt.show

acc = training.history['accuracy']
val_acc = training.history['val_accuracy']
loss = training.history['loss']
val_loss = training.history['val_loss']

("Overall Accuracy of PHDS model is %2f% {} %".format(acc[-1]*100))

import matplotlib.pyplot as plt  
from sklearn.datasets import make_classification
from sklearn.metrics import plot_confusion_matrix
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC

X, y = make_classification()
X_train, X_test, y_train, y_test = train_test_split(X, y)

clf = SVC(random_state=0)
clf.fit(X_train, y_train)
SVC(random_state=0)

plot_confusion_matrix(clf, X_test, y_test)  
plt.title('PHDS Matrix')
plt.show()

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix
#Fit the model
logreg = LogisticRegression(C=1e5)
logreg.fit(X,y)
#Generate predictions with the model using our X values
y_pred = logreg.predict(X)
#Get the confusion matrix
cf_matrix = confusion_matrix(y, y_pred)
print(cf_matrix)

import seaborn as sns
sns.heatmap(cf_matrix, annot=True)

cm = metrics.confusion_matrix(y, y_pred)
print(cm)

plt.figure(figsize=(5,5))
sns.heatmap(cm, annot=True, fmt=".3f", linewidths=.5, square = True, cmap = 'Blues_r')
plt.ylabel('Actual label')
plt.xlabel('Predicted label')
plt.title('PHDS')

skplt.metrics.plot_confusion_matrix(y, y_pred, normalize=True)
plt.title('PHDS Confusion Matrix')
plt.show()

"""**predict the image**"""

import numpy as np
from google.colab import files
from keras.preprocessing import image

uploaded = files.upload()

for fn in uploaded.keys():
 
  # predicting images
  path = '/content/' + fn
  img = image.load_img(path, target_size=(150, 150))
  x = image.img_to_array(img)
  x = np.expand_dims(x, axis=0)

  images = np.vstack([x])
  classes = model.predict(images, batch_size=10)
  print(classes[0])
  if classes[0]>0.5:
    print("Your uploaded file is: "+ fn + " and this is an Unhealthy leaf")
  else:
    print("Your uploaded file is: "+ fn + " and this is a Healthy leaf")